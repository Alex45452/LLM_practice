{"cells":[{"cell_type":"code","source":["!git clone https://huggingface.co/datasets/nyu-mll/glue\n","!git clone https://github.com/RefalMachine/llmtf_open\n","%cd llmtf_open"],"metadata":{"id":"vuzyViB6anP7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mnIt0Nc1UB1P","outputId":"d022bbd7-d523-47cb-c8a3-afd3031d5854"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["conversation_configs\t      README.md\n","Dockerfile\t\t      requirements.txt\n","eval_grammar.py\t\t      run_evaluate_multinode_multigpu.py\n","evaluate_model.py\t      run_evaluate_multinode_multigpu.sh\n","examples\t\t      run_evaluate_singlenode_multigpu.sh\n","huggingface_tokenizers_cache  run_llm_as_a_judge.py\n","instruct_unsloth\t      todo.txt\n","llm_as_a_judge_baselines      trained_qwen_model_lora\n","llmtf\t\t\t      unsloth_compiled_cache\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZkyfKM5bNHt","outputId":"35a802ee-1f8a-4834-d553-c28e2118d113"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-78238dd4f3d1>:26: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n","\n","Please restructure your imports with 'import unsloth' at the top of your file.\n","  from unsloth import FastLanguageModel, UnslothTrainingArguments, UnslothTrainer\n"]},{"output_type":"stream","name":"stdout","text":["ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ü¶• Unsloth Zoo will now patch everything to make training faster!\n"]}],"source":["import random\n","import codecs\n","import torch\n","import json\n","import re\n","import copy\n","import numpy as np\n","import os\n","from tqdm import tqdm\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForCausalLM,\n","    DataCollatorForTokenClassification,\n","    AutoConfig,\n",")\n","from transformers import (\n","    Trainer,\n","    TrainingArguments,\n","    logging,\n","    TrainerCallback,\n","    TrainerState,\n","    TrainerControl,\n","    BitsAndBytesConfig,\n",")\n","from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n","from unsloth import FastLanguageModel, UnslothTrainingArguments, UnslothTrainer\n","\n","from peft import get_peft_model, LoraConfig\n","from peft import prepare_model_for_kbit_training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IFxKmbf2usFx"},"outputs":[],"source":["from typing import List, Dict\n","\n","from torch.utils.data import Dataset\n","\n","\n","class ChatDataset(Dataset):\n","    def __init__(\n","        self,\n","        original_records: List[Dict],\n","        tokenizer: AutoTokenizer,\n","        max_tokens_count: int,\n","        sample_rate: float = 1.0,\n","        only_target_loss: bool = True,\n","        add_global_bos: bool = True,\n","        add_global_eos: bool = True,\n","        labels_pad_token_id: int = -100\n","    ):\n","        self.original_records = original_records\n","        self.sample_rate = sample_rate\n","        self.tokenizer = tokenizer\n","        self.max_tokens_count = max_tokens_count\n","        self.only_target_loss = only_target_loss\n","        self.labels_pad_token_id = labels_pad_token_id\n","        self.add_global_bos = add_global_bos\n","        self.add_global_eos = add_global_eos\n","        self.is_printed = False\n","\n","        self.records = []\n","        for record in tqdm(original_records):\n","            # if random.random() > self.sample_rate:\n","            #     continue\n","            # –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º –≤ —É—Å–ª–æ–≤–∏—è—Ö –∑–∞–¥–∞—á–∏\n","            tensors = self.convert_record(record)\n","            if tensors is None:\n","                continue\n","            self.records.append(tensors)\n","\n","    def __len__(self):\n","        return len(self.records)\n","\n","    def __getitem__(self, index):\n","        return self.records[index]\n","\n","    def get_tokens(self, messages):\n","        #print(messages)\n","        tokens = self.tokenizer.apply_chat_template(\n","            messages,\n","            add_special_tokens=False,\n","            tokenize=True,\n","            add_generation_prompt=False,\n","        )\n","        if tokens[0] == self.tokenizer.bos_token_id:\n","            tokens = tokens[1:]\n","        # –ø–æ—á–µ–º—É –º—ã –æ–±—Ä–µ–∑–∞–µ–º —Ç–æ–∫–µ–Ω –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫–∏?\n","        return tokens\n","\n","    def convert_record(self, record):\n","\n","        messages = []\n","\n","        message_user = f\"Your task is to determine the acceptability of the text for the English language in terms of syntax, morphology and semantics. The answer should be one number: 0 or 1, where 0 means the sentence is not acceptable from the point of view of the English language, 1 means it is acceptable.\\nText:{record['sentence']}\"\n","        message_bot_train = f\"Answer: {record['label']}\"\n","\n","        messages.append({'role': 'user', 'content': message_user})\n","        messages.append({'role': 'bot', 'content': message_bot_train})\n","        # –∫ —Å–æ–æ–±—â–µ–Ω–∏—é –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è —á–∞—Ç —Ç–µ–º–ø–ª–µ–π—Ç\n","        input_ids = self.get_tokens(messages)\n","        labels = input_ids\n","\n","        # –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∞–∫—Å. –¥–ª–∏–Ω–Ω—É —á–∞—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å—é\n","        if len(input_ids) > self.max_tokens_count - 2:\n","            return None\n","        # –≤ —ç—Ç–æ–º –±–ª–æ–∫–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –≤–µ—Å—å —á–∞—Ç/–Ω–∞ –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏\n","        labels_mask = [\n","            self.labels_pad_token_id for _ in range(len(input_ids))\n","        ]\n","        if (\n","            self.only_target_loss\n","        ):\n","            message_labels = labels_mask\n","\n","\n","        if not input_ids:\n","            return None\n","\n","        # –Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è—Ç–Ω–æ –∑–∞—á–µ–º —ç—Ç–æ –∑–¥–µ—Å—å\n","        # original_input_ids = self.get_tokens(record[\"sentence\"])\n","        # if input_ids != original_input_ids[: len(input_ids)]:\n","        #     print(input_ids)\n","        #     print(original_input_ids[: len(input_ids)])\n","        # assert input_ids == original_input_ids[: len(input_ids)]\n","\n","        # –¥–æ–±–∞–≤–ª—è–µ–º –≥–ª–∞–±–∞–ª—å–Ω—ã–π bos\n","        if self.add_global_bos and input_ids[0] != self.tokenizer.bos_token_id:\n","            input_ids.insert(0, self.tokenizer.bos_token_id)\n","            labels.insert(0, self.labels_pad_token_id)\n","\n","        # –æ–±—Ä–µ–∑–∞–µ–º —Å–ø–µ—Ü—Å–∏–≤–æ–ª –ø–æ—Å–ª–µ eos\n","        if input_ids[-2] == self.tokenizer.eos_token_id:\n","            input_ids = input_ids[:-1]\n","            labels = labels[:-1]\n","\n","        # –¥–æ–±–∞–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π eos\n","        if self.add_global_eos and input_ids[-1] != self.tokenizer.eos_token_id:\n","            input_ids.append(self.tokenizer.eos_token_id)\n","            labels.append(self.tokenizer.eos_token_id)\n","\n","        # –≤—ã–≤–æ–¥–∏–º 1 –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –¥–ª—è —Å–≤–µ—Ä–∫–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —á–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞\n","        if not self.is_printed:\n","            print(input_ids)\n","            print(labels)\n","            print(\n","                \"Full prompt:\" +\n","                self.tokenizer.decode(input_ids, skip_special_tokens=False)\n","            )\n","            assert '\\n' in self.tokenizer.decode(input_ids, skip_special_tokens=False)\n","            self.is_printed = True\n","\n","\n","        input_ids = torch.LongTensor(input_ids)\n","        labels = torch.LongTensor(labels)\n","        attention_mask = input_ids.new_ones(input_ids.size())\n","        assert (\n","            input_ids.size(0)\n","            == labels.size(0)\n","            == attention_mask.size(0)\n","            <= self.max_tokens_count\n","        )\n","        return {\n","            \"input_ids\": input_ids,\n","            \"labels\": labels,\n","            \"attention_mask\": attention_mask,\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1UulUnL8GW9","outputId":"aeba1f29-6bcd-4029-93fd-4a18bfe7552d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 8551\n","    })\n","    validation: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 1043\n","    })\n","    test: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 1063\n","    })\n","})"]},"metadata":{},"execution_count":14}],"source":["from datasets import load_dataset\n","dataset = load_dataset('nyu-mll/glue','cola')\n","dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QwBC07pwrExf","outputId":"5f84e872-6008-4f64-bf57-a7efaf226567"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 900\n","    })\n","    test: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 100\n","    })\n","})"]},"metadata":{},"execution_count":15}],"source":["dataset = dataset['train'].select(range(1000))\n","dataset = dataset.train_test_split(test_size=0.1)\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mawxTB-n9oGz"},"outputs":[],"source":["os.environ[\"WANDB_DISABLED\"] = \"true\"\n","# –æ—Ç–∫–ª—é—á–∞–µ–º —Å–µ—Ä–≤–∏—Å WandB —á—Ç–æ –±—ã –æ–Ω –Ω–µ —Å–æ–±–∏—Ä–∞–ª —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":123},"id":"w-Xda5PL942A","outputId":"ffe8c4fc-8a91-4be6-e865-a7e92dbc02c5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}],"source":["# –∏—Å–ø–æ–ª—å–∑—É–µ–º —á–∞—Ç —Ç–µ–º–ø–ª–µ–π—Ç –æ—Ç Ruadapt –≤–µ—Ä—Å–∏–∏ —Ç–∞–∫ –∫–∞–∫ –æ–Ω –Ω–µ –ø—Ä–æ–∫–∏–¥—ã–≤–∞–µ—Ç system —á–∞—Å—Ç—å –≤ –ø—Ä–æ–º–ø—Ç\n","tokenizer = AutoTokenizer.from_pretrained('RefalMachine/RuadaptQwen2.5-7B-Lite-Beta')\n","chat_template = tokenizer.chat_template\n","chat_template"]},{"cell_type":"code","source":["model_name = 'Qwen/Qwen2.5-1.5B-Instruct'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"],"metadata":{"id":"cDg5-wmRwo8H"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J1z4UZt399mN","outputId":"fd85f3e4-417c-4445-a1d5-1a3cda75520f"},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.3.19: Fast Qwen2 patching. Transformers: 4.48.3.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}],"source":["# –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å unsloth\n","max_tokens_count = 1024\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=model_name,\n","    max_seq_length=max_tokens_count,\n","    dtype=torch.float16,\n","    load_in_4bit=True,\n","    attn_implementation=\"sdpa\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXuHgw7j_Zaw"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.chat_template = chat_template\n","tokenizer.padding_side = 'left'\n","# —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏ —á–∞—Ç —Ç–µ–º–ø–ª–µ–π—Ç"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8WwVg96_dI9","outputId":"752726d3-fbb1-4a41-c652-45cbbf759017"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 29%|‚ñà‚ñà‚ñâ       | 263/900 [00:00<00:00, 1334.70it/s]"]},{"output_type":"stream","name":"stdout","text":["[151644, 872, 198, 7771, 3383, 374, 311, 8253, 279, 4193, 2897, 315, 279, 1467, 369, 279, 6364, 4128, 304, 3793, 315, 19482, 11, 78512, 323, 52694, 13, 576, 4226, 1265, 387, 825, 1372, 25, 220, 15, 476, 220, 16, 11, 1380, 220, 15, 3363, 279, 11652, 374, 537, 21555, 504, 279, 1459, 315, 1651, 315, 279, 6364, 4128, 11, 220, 16, 3363, 432, 374, 21555, 624, 1178, 57155, 2908, 1052, 311, 387, 264, 883, 304, 429, 13551, 13, 151645]\n","[151644, 872, 198, 7771, 3383, 374, 311, 8253, 279, 4193, 2897, 315, 279, 1467, 369, 279, 6364, 4128, 304, 3793, 315, 19482, 11, 78512, 323, 52694, 13, 576, 4226, 1265, 387, 825, 1372, 25, 220, 15, 476, 220, 16, 11, 1380, 220, 15, 3363, 279, 11652, 374, 537, 21555, 504, 279, 1459, 315, 1651, 315, 279, 6364, 4128, 11, 220, 16, 3363, 432, 374, 21555, 624, 1178, 57155, 2908, 1052, 311, 387, 264, 883, 304, 429, 13551, 13, 151645]\n","Full prompt:<|im_start|>user\n","Your task is to determine the acceptability of the text for the English language in terms of syntax, morphology and semantics. The answer should be one number: 0 or 1, where 0 means the sentence is not acceptable from the point of view of the English language, 1 means it is acceptable.\n","Text:I consider there to be a man in that garden.<|im_end|>\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 900/900 [00:00<00:00, 1349.03it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 1429.45it/s]"]},{"output_type":"stream","name":"stdout","text":["[151644, 872, 198, 7771, 3383, 374, 311, 8253, 279, 4193, 2897, 315, 279, 1467, 369, 279, 6364, 4128, 304, 3793, 315, 19482, 11, 78512, 323, 52694, 13, 576, 4226, 1265, 387, 825, 1372, 25, 220, 15, 476, 220, 16, 11, 1380, 220, 15, 3363, 279, 11652, 374, 537, 21555, 504, 279, 1459, 315, 1651, 315, 279, 6364, 4128, 11, 220, 16, 3363, 432, 374, 21555, 624, 1178, 57155, 4961, 3432, 58234, 10244, 13, 151645]\n","[151644, 872, 198, 7771, 3383, 374, 311, 8253, 279, 4193, 2897, 315, 279, 1467, 369, 279, 6364, 4128, 304, 3793, 315, 19482, 11, 78512, 323, 52694, 13, 576, 4226, 1265, 387, 825, 1372, 25, 220, 15, 476, 220, 16, 11, 1380, 220, 15, 3363, 279, 11652, 374, 537, 21555, 504, 279, 1459, 315, 1651, 315, 279, 6364, 4128, 11, 220, 16, 3363, 432, 374, 21555, 624, 1178, 57155, 4961, 3432, 58234, 10244, 13, 151645]\n","Full prompt:<|im_start|>user\n","Your task is to determine the acceptability of the text for the English language in terms of syntax, morphology and semantics. The answer should be one number: 0 or 1, where 0 means the sentence is not acceptable from the point of view of the English language, 1 means it is acceptable.\n","Text:I reported having kissed Mary.<|im_end|>\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["only_target_loss = True\n","\n","datasets = []\n","for split in ('train','test'):\n","    datasets.append(\n","        ChatDataset(\n","            dataset[split],\n","            tokenizer,\n","            max_tokens_count=max_tokens_count,\n","            sample_rate=1.0,\n","            only_target_loss=only_target_loss,\n","            add_global_eos=False,\n","            add_global_bos=False\n","        )\n","    )\n","train_dataset, val_dataset = datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O0oUAShK_0Ft","colab":{"base_uri":"https://localhost:8080/"},"outputId":"72c17b1f-e80f-4c9f-a469-8dcef5832e45"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["GenerationConfig {\n","  \"do_sample\": true,\n","  \"eos_token_id\": 151645,\n","  \"max_new_tokens\": 64,\n","  \"pad_token_id\": 151643,\n","  \"temperature\": 0.1,\n","  \"top_k\": 20,\n","  \"top_p\": 0.8\n","}"]},"metadata":{},"execution_count":26}],"source":["from transformers import GenerationConfig\n","\n","# def generate(messages, model, tokenizer, generation_config):\n","#     print(tokenizer.apply_chat_template(messages, add_special_tokens=False, add_generation_prompt=True, tokenize=False))\n","#     input_ids = tokenizer.apply_chat_template(messages, return_tensors='pt', add_special_tokens=False, add_generation_prompt=True)\n","#     input_ids = input_ids.to(model.device)\n","#     with torch.no_grad():\n","#         output_ids = model.generate(\n","#             input_ids,\n","#             generation_config=generation_config\n","#         )\n","#     outputs = []\n","#     for sample_output_ids, sample_input_ids in zip(output_ids, input_ids):\n","#         sample_output_ids = sample_output_ids[len(sample_input_ids):]\n","#         sample_output = tokenizer.decode(sample_output_ids, skip_special_tokens=True)\n","#         outputs.append(sample_output)\n","\n","#     if len(outputs) == 1:\n","#         outputs = outputs[0]\n","#     return outputs\n","\n","\n","\n","generation_config = GenerationConfig.from_dict(\n","    {\n","        'top_k': 20,\n","        'top_p': 0.8,\n","        'temperature': 0.1,\n","        'repetition_penalty': 1.0,\n","        'max_new_tokens': 64,\n","        'do_sample': True,\n","        'pad_token_id': tokenizer.pad_token_id,\n","        'bos_token_id': tokenizer.bos_token_id,\n","        'eos_token_id': tokenizer.eos_token_id\n","    }\n",")\n","generation_config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75caqlan_4qX"},"outputs":[],"source":["lora_config = {\n","    \"r\": 32,\n","    \"lora_alpha\": 16,\n","    \"lora_dropout\": 0.0,\n","    \"bias\": \"none\",\n","    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n","    \"use_gradient_checkpointing\": \"unsloth\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WYPXTJnA_6rw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc6d6966-645d-436c-eb63-9ed757a71fc6"},"outputs":[{"output_type":"stream","name":"stderr","text":["Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters\n","are not enabled or a bias term (like in Qwen) is used.\n","Unsloth 2025.3.19 patched 28 layers with 28 QKV layers, 28 O layers and 0 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model, **lora_config, max_seq_length=max_tokens_count\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJ_m-CstADXu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"51db5ca8-bd22-4f3a-fb19-0bcbc868bb5a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]}],"source":["training_args = {\n","    \"per_device_train_batch_size\": 1,\n","    \"per_device_eval_batch_size\": 1,\n","    \"gradient_accumulation_steps\": 8,\n","    \"eval_steps\": 16,\n","    \"save_steps\": 128,\n","    \"logging_steps\": 16,\n","    \"learning_rate\": 0.00005,\n","    \"num_train_epochs\": 1,\n","    \"lr_scheduler_type\": \"cosine\",\n","    \"warmup_steps\": 16,\n","    \"bf16\": False,\n","    \"fp16\": True,\n","    \"optim\": \"paged_adamw_8bit\",\n","    \"save_total_limit\": 1,\n","    \"seed\": 1337,\n","    \"max_grad_norm\": 1.0,\n","    \"weight_decay\": 0.05\n","}\n","training_args = UnslothTrainingArguments(output_dir='./instruct_unsloth', **training_args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kp6a82q6AGw3"},"outputs":[],"source":["from unsloth.trainer import _create_unsloth_optimizer\n","class CustomTrainer(Trainer):\n","    def create_optimizer(self):\n","        embedding_learning_rate = getattr(self.args, \"embedding_learning_rate\", None)\n","        if embedding_learning_rate is None:\n","            return super().create_optimizer()\n","        if self.optimizer is None:\n","            optimizer_cls, optimizer_kwargs = Trainer.get_optimizer_cls_and_kwargs(self.args)\n","            self.optimizer = _create_unsloth_optimizer(\n","                self.model,\n","                optimizer_cls,\n","                optimizer_kwargs,\n","                embedding_learning_rate,\n","            )\n","        return self.optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBqnasxbAitD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_Gyla_tAJV2","colab":{"base_uri":"https://localhost:8080/","height":416},"outputId":"353a9ec2-12b9-476f-885b-051b16d557bc"},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 900 | Num Epochs = 1 | Total steps = 112\n","O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 8\n","\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 8 x 1) = 8\n"," \"-____-\"     Trainable parameters = 8,716,288/5,000,000,000 (0.17% trained)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [112/112 08:39, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>16</td>\n","      <td>2.878400</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>2.380100</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>1.742300</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>1.162300</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.884600</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.833600</td>\n","    </tr>\n","    <tr>\n","      <td>112</td>\n","      <td>0.844300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=112, training_loss=1.532220951148442, metrics={'train_runtime': 528.6191, 'train_samples_per_second': 1.703, 'train_steps_per_second': 0.212, 'total_flos': 585597947092992.0, 'train_loss': 1.532220951148442, 'epoch': 0.9955555555555555})"]},"metadata":{},"execution_count":31}],"source":["# –ó–∞–Ω–∏–º–∞–µ—Ç –≤ –ø–∞–º—è—Ç–∏ –≤—Å–µ–≥–æ 3.5GB –¥–ª—è 1.5B –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏!\n","trainer = data_collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=8)\n","trainer = CustomTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=data_collator,\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Se2Odj33Acvi"},"outputs":[],"source":["model.save_pretrained('./trained_qwen_model_lora')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmVbFMt_AeXS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f5d99ec-bb7b-44ff-b278-0f9a5944ea1e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('./trained_qwen_model_lora/tokenizer_config.json',\n"," './trained_qwen_model_lora/special_tokens_map.json',\n"," './trained_qwen_model_lora/vocab.json',\n"," './trained_qwen_model_lora/merges.txt',\n"," './trained_qwen_model_lora/added_tokens.json',\n"," './trained_qwen_model_lora/tokenizer.json')"]},"metadata":{},"execution_count":33}],"source":["tokenizer.save_pretrained('./trained_qwen_model_lora')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jS407LD0Af6q","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c5a4a1a0-0470-4104-bbdc-5c3d3aa0a7fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["adapter_config.json\t   merges.txt\t\t    tokenizer_config.json\n","adapter_model.safetensors  README.md\t\t    tokenizer.json\n","added_tokens.json\t   special_tokens_map.json  vocab.json\n"]}],"source":["!ls trained_qwen_model_lora"]},{"cell_type":"markdown","source":["–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ–∞–Ω—Å\n"],"metadata":{"id":"i0Z7SGdtR1Rs"}},{"cell_type":"code","source":["%cd llmtf_open"],"metadata":{"id":"-Yk-Wjybx3IF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0715f1cd-985e-4a3b-b7ce-2d774351d27b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/llmtf_open\n"]}]},{"cell_type":"code","source":["from llmtf.model import HFModel\n","from typing import Dict, List, Tuple\n","from llmtf.metrics import mean\n","from llmtf.base import SimpleFewShotHFTask\n","from sklearn.metrics import matthews_corrcoef"],"metadata":{"id":"LnvPbkJYxcQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u258KIEWbIiS"},"outputs":[],"source":["class GlueColaTask(SimpleFewShotHFTask):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.method = 'calculate_tokens_proba'\n","        self._max_new_tokens = 1\n","\n","    @classmethod\n","    def name(cls):\n","        return 'glue/cola'\n","\n","    @property\n","    def choices(self):\n","        return [\"0\", \"1\"]\n","\n","    def aggregation(self) -> Dict:\n","        return {\"acc\": mean, \"mcc\": lambda data: matthews_corrcoef([d[0] for d in data],[d[1] for d in data])}\n","\n","    def dataset_args(self) -> Dict:\n","        return {'path': '../glue/cola'}\n","\n","\n","    def evaluate(self, sample, y_pred) -> Dict:\n","        y_true = str(sample['label'])\n","        y_pred = sorted([pair for pair in y_pred.items()], key=lambda x: -x[1])[0][0]\n","        return {\"acc\": y_true == y_pred, \"mcc\": [y_true, y_pred]}\n","\n","    def test_split_name(self) -> str:\n","        return 'validation'\n","\n","    def prompt_split_name(self) -> str:\n","        return 'train'\n","\n","    def create_messages(self, sample, with_answer=False) -> List[Dict]:\n","\n","        messages = []\n","\n","        instruction_user = \"Your task is to determine the acceptability of the text for the English language in terms of syntax, morphology and semantics. The answer should be one number: 0 or 1, where 0 means the sentence is not acceptable from the point of view of the English language, 1 means it is acceptable.\\nText:{sentence}\"\n","        instruction_bot = \"Answer:\"\n","\n","        messages.append({'role': 'user', 'content': instruction_user.format(**sample)})\n","        messages.append({'role': 'bot', 'content': instruction_bot})\n","\n","        return messages"]},{"cell_type":"code","source":["task = GlueColaTask()"],"metadata":{"id":"sj_fxWjMNWLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Xzh5X5_b7Vn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"289bd124-2f0d-484d-b904-636f2cb8cb68"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n","  warnings.warn(\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151665/151665 [00:00<00:00, 284132.59it/s]\n","INFO: 2025-04-18 00:47:22,104: llmtf.base.hfmodel: Set eos_token_id in generation_config to [151645]\n","INFO:llmtf.base.hfmodel:Set eos_token_id in generation_config to [151645]\n","WARNING: 2025-04-18 00:47:22,110: llmtf.base.hfmodel: Global prefix is equal to empty string!\n","WARNING:llmtf.base.hfmodel:Global prefix is equal to empty string!\n","INFO: 2025-04-18 00:47:22,114: llmtf.base.hfmodel: Model id: ./trained_qwen_model_lora\n","INFO:llmtf.base.hfmodel:Model id: ./trained_qwen_model_lora\n","INFO: 2025-04-18 00:47:22,118: llmtf.base.hfmodel: Leading space: False\n","INFO:llmtf.base.hfmodel:Leading space: False\n"]}],"source":["model_name = \"./trained_qwen_model_lora\"\n","model = HFModel(device_map=\"cuda\",attn_implementation=\"sdpa\")\n","model.from_pretrained(model_name)"]},{"cell_type":"code","source":["model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n","model = HFModel(device_map=\"cuda\",attn_implementation=\"sdpa\")\n","model.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321,"referenced_widgets":["503c901bae2b4595a06254fca02e5f82","b5c0d5dd14994d649446b84ef372b211","7b82d69d26c0471ab154503916da5e2b","12072e972e0b4cee9e2fe3fcc8144fd2","a28999d553a54411a3614f7e32bd6d01","def763541d624e05ac930634f577a582","9e7a45b525d84fb9a2cfd6d4290c5481","9b95d3631bc34ced92f99737a0c4d0b5","1b42cfd34b2f4ddfb294c108244e5de3","a3b719f2736f4f23b3182d694e705fcb","d9b8e0202e894ef2b979d31fbcb730c5","bff05672c1f740d59b7005fa179c77d9","6781bff4a25d4f8cad28132a7c4a25b2","a5177ef006dc4736af9433faacb83822","dc890108a9ce46b3a7ee32a866843685","d10ade5db87d46569d70bec23ac94513","c4c6f7eb85b94c258e22eec1ecf41a3d","01212fe2b46e47fb8c22e864d7e626df","9f23132297604576ac0eaaaef6cf579b","66d50916b8bf49f89c8e172482ece5ad","b7029268316d48239294db78282a3cf7","5f06a2849cdb4f67856422b5f182b64e","705bcc93945343878c47d8b906e63ff1","46d2baca873e4b209b0432f929de38c0","1f9ed604c26f404da6c9125f292421ca","a2e2a5bc38a54447948ac063ac50e96f","8d984162830d4720a83641ce49441d21","399e08741621415b940bdb04aaeac11f","490b6c7afdc7474f8f786a44bd3efe8d","a2bc10dea1644a0e9137f4260a564928","81a35d18b7dc447ebd90400736134cc3","57d7ffb267904838b0ad6930ceb5156a","2a1cee8108064eeea0be6c62c3f599c2"]},"id":"knE5T3uz1yO0","outputId":"aaedd454-8ecf-413b-cade-a0d97142b5d9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"503c901bae2b4595a06254fca02e5f82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff05672c1f740d59b7005fa179c77d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"705bcc93945343878c47d8b906e63ff1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["FORCES SYSTEM PROMPT AT START=<|im_start|>system\n","You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 151665/151665 [00:00<00:00, 283161.50it/s]\n","INFO: 2025-04-18 00:30:04,257: llmtf.base.hfmodel: Set eos_token_id in generation_config to [151645]\n","INFO:llmtf.base.hfmodel:Set eos_token_id in generation_config to [151645]\n","WARNING: 2025-04-18 00:30:04,263: llmtf.base.hfmodel: Global prefix is equal to empty string!\n","WARNING:llmtf.base.hfmodel:Global prefix is equal to empty string!\n","INFO: 2025-04-18 00:30:04,268: llmtf.base.hfmodel: Model id: Qwen/Qwen2.5-1.5B-Instruct\n","INFO:llmtf.base.hfmodel:Model id: Qwen/Qwen2.5-1.5B-Instruct\n","INFO: 2025-04-18 00:30:04,272: llmtf.base.hfmodel: Leading space: False\n","INFO:llmtf.base.hfmodel:Leading space: False\n"]}]},{"cell_type":"code","source":["from llmtf.evaluator import Evaluator\n","evaluator = Evaluator()\n","\n","evaluator.evaluate_dataset(\n","    task=task,\n","    model=model,\n","    output_dir='../cola-qwen-no_finetune',\n","    max_len=4000,\n","    few_shot_count=0,\n","    generation_config=None, # will use model.generation_config by default\n","    batch_size=4,\n","    max_sample_per_dataset=200\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3w_s6mb-SGm6","outputId":"dc8f836a-127b-451a-fa74-092533007dbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO: 2025-04-18 00:47:22,171: llmtf.base.hfmodel: Updated generation_config.eos_token_id: [151645]\n","INFO:llmtf.base.hfmodel:Updated generation_config.eos_token_id: [151645]\n","INFO: 2025-04-18 00:47:22,174: llmtf.base.hfmodel: Updated generation_config.stop_strings: ['<|im_end|>']\n","INFO:llmtf.base.hfmodel:Updated generation_config.stop_strings: ['<|im_end|>']\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 1315.18it/s]\n","INFO: 2025-04-18 00:47:22,398: llmtf.base.glue/cola: Loading Dataset: 0.22s\n","INFO:llmtf.base.glue/cola:Loading Dataset: 0.22s\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:25<00:00,  1.94it/s]\n","INFO: 2025-04-18 00:47:48,168: llmtf.base.glue/cola: Processing Dataset: 25.77s\n","INFO:llmtf.base.glue/cola:Processing Dataset: 25.77s\n","INFO: 2025-04-18 00:47:48,170: llmtf.base.glue/cola: Results for glue/cola:\n","INFO:llmtf.base.glue/cola:Results for glue/cola:\n","INFO: 2025-04-18 00:47:48,190: llmtf.base.glue/cola: {'acc': 0.765, 'mcc': 0.5142362160741519}\n","INFO:llmtf.base.glue/cola:{'acc': 0.765, 'mcc': 0.5142362160741519}\n"]}]},{"cell_type":"code","source":["!cat ../cola-qwen-clear/glue_cola_total.jsonl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83_9y9R_TORi","outputId":"3ebaea63-a987-4a49-cc2c-676a7caca83d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"task_name\": \"glue/cola\",\n","    \"results\": {\n","        \"acc\": 0.745,\n","        \"mcc\": 0.4985588860372235\n","    },\n","    \"leaderboard_result\": 0.6217794430186118\n","}\n"]}]},{"cell_type":"code","source":["!cat ../cola-qwen-lora-16/glue_cola_total.jsonl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxSoI_QMTOaA","outputId":"6ac9fd15-baf1-4ade-c9d2-81635a4aeb6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"task_name\": \"glue/cola\",\n","    \"results\": {\n","        \"acc\": 0.76,\n","        \"mcc\": 0.5110628565334214\n","    },\n","    \"leaderboard_result\": 0.6355314282667107\n","}\n"]}]},{"cell_type":"code","source":["!cat ../cola-qwen-lora-32/glue_cola_total.jsonl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTcZFpYYXiLC","outputId":"25761c29-592a-4898-f35d-2b4580b0514f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"task_name\": \"glue/cola\",\n","    \"results\": {\n","        \"acc\": 0.765,\n","        \"mcc\": 0.5142362160741519\n","    },\n","    \"leaderboard_result\": 0.639618108037076\n","}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"zHwMy0XoXhno"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["–≠—Ç—É –ø—Ä–æ–±–ª–µ–º—É –Ω–∞–¥–æ —Ä–µ—à–∏—Ç—å, —è –Ω–µ –ø–æ–Ω–∏–º–∞—é, –ø–æ—á–µ–º—É –æ–Ω–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç.\n","–í –∫–∞—á–µ—Å—Ç–≤–µ —Ä–µ—à–µ–Ω–∏—è —è –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏–ª assert. –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–±—ã—á–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å–æ–≤–ø–∞–ª–∏ —Å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º–∏."],"metadata":{"id":"VXzRnhJtSQus"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7sy0oMgqcKD8","colab":{"base_uri":"https://localhost:8080/","height":529},"outputId":"b1dcae0c-69ae-401b-fd32-dc4d37063c5b"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO: 2025-04-18 00:24:48,840: llmtf.base.hfmodel: Updated generation_config.eos_token_id: [151645]\n","INFO:llmtf.base.hfmodel:Updated generation_config.eos_token_id: [151645]\n","INFO: 2025-04-18 00:24:48,842: llmtf.base.hfmodel: Updated generation_config.stop_strings: ['<|im_end|>']\n","INFO:llmtf.base.hfmodel:Updated generation_config.stop_strings: ['<|im_end|>']\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 1269.37it/s]\n","INFO: 2025-04-18 00:24:49,059: llmtf.base.glue/cola: Loading Dataset: 0.21s\n","INFO:llmtf.base.glue/cola:Loading Dataset: 0.21s\n"," 14%|‚ñà‚ñç        | 7/50 [00:04<00:26,  1.63it/s]\n","INFO: 2025-04-18 00:24:53,350: llmtf.base.glue/cola: Processing Dataset: 4.29s\n","INFO:llmtf.base.glue/cola:Processing Dataset: 4.29s\n"]},{"output_type":"error","ename":"AssertionError","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-31b7896221d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m evaluator.evaluate_dataset(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/llmtf_open/llmtf/evaluator.py\u001b[0m in \u001b[0;36mevaluate_dataset\u001b[0;34m(self, task, model, output_dir, max_len, few_shot_count, generation_config, batch_size, max_sample_per_dataset)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mmessages_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmessages_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/llmtf_open/llmtf/model.py\u001b[0m in \u001b[0;36mcalculate_tokens_proba_batch\u001b[0;34m(self, messages, tokens_of_interest, incomplete_last_bot_message)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mnext_token_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens_of_interest_ids_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: "]}],"source":["from llmtf.evaluator import Evaluator\n","evaluator = Evaluator()\n","\n","evaluator.evaluate_dataset(\n","    task=task,\n","    model=model,\n","    output_dir='../cola-qwen-no_l',\n","    max_len=4000,\n","    few_shot_count=0,\n","    generation_config=None, # will use model.generation_config by default\n","    batch_size=4,\n","    max_sample_per_dataset=200\n",")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"503c901bae2b4595a06254fca02e5f82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5c0d5dd14994d649446b84ef372b211","IPY_MODEL_7b82d69d26c0471ab154503916da5e2b","IPY_MODEL_12072e972e0b4cee9e2fe3fcc8144fd2"],"layout":"IPY_MODEL_a28999d553a54411a3614f7e32bd6d01"}},"b5c0d5dd14994d649446b84ef372b211":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_def763541d624e05ac930634f577a582","placeholder":"‚Äã","style":"IPY_MODEL_9e7a45b525d84fb9a2cfd6d4290c5481","value":"config.json:‚Äá100%"}},"7b82d69d26c0471ab154503916da5e2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b95d3631bc34ced92f99737a0c4d0b5","max":660,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b42cfd34b2f4ddfb294c108244e5de3","value":660}},"12072e972e0b4cee9e2fe3fcc8144fd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3b719f2736f4f23b3182d694e705fcb","placeholder":"‚Äã","style":"IPY_MODEL_d9b8e0202e894ef2b979d31fbcb730c5","value":"‚Äá660/660‚Äá[00:00&lt;00:00,‚Äá18.6kB/s]"}},"a28999d553a54411a3614f7e32bd6d01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"def763541d624e05ac930634f577a582":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e7a45b525d84fb9a2cfd6d4290c5481":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b95d3631bc34ced92f99737a0c4d0b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b42cfd34b2f4ddfb294c108244e5de3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3b719f2736f4f23b3182d694e705fcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9b8e0202e894ef2b979d31fbcb730c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bff05672c1f740d59b7005fa179c77d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6781bff4a25d4f8cad28132a7c4a25b2","IPY_MODEL_a5177ef006dc4736af9433faacb83822","IPY_MODEL_dc890108a9ce46b3a7ee32a866843685"],"layout":"IPY_MODEL_d10ade5db87d46569d70bec23ac94513"}},"6781bff4a25d4f8cad28132a7c4a25b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4c6f7eb85b94c258e22eec1ecf41a3d","placeholder":"‚Äã","style":"IPY_MODEL_01212fe2b46e47fb8c22e864d7e626df","value":"model.safetensors:‚Äá100%"}},"a5177ef006dc4736af9433faacb83822":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f23132297604576ac0eaaaef6cf579b","max":3087467144,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66d50916b8bf49f89c8e172482ece5ad","value":3087467144}},"dc890108a9ce46b3a7ee32a866843685":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7029268316d48239294db78282a3cf7","placeholder":"‚Äã","style":"IPY_MODEL_5f06a2849cdb4f67856422b5f182b64e","value":"‚Äá3.09G/3.09G‚Äá[00:30&lt;00:00,‚Äá61.2MB/s]"}},"d10ade5db87d46569d70bec23ac94513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4c6f7eb85b94c258e22eec1ecf41a3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01212fe2b46e47fb8c22e864d7e626df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f23132297604576ac0eaaaef6cf579b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66d50916b8bf49f89c8e172482ece5ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7029268316d48239294db78282a3cf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f06a2849cdb4f67856422b5f182b64e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"705bcc93945343878c47d8b906e63ff1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46d2baca873e4b209b0432f929de38c0","IPY_MODEL_1f9ed604c26f404da6c9125f292421ca","IPY_MODEL_a2e2a5bc38a54447948ac063ac50e96f"],"layout":"IPY_MODEL_8d984162830d4720a83641ce49441d21"}},"46d2baca873e4b209b0432f929de38c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_399e08741621415b940bdb04aaeac11f","placeholder":"‚Äã","style":"IPY_MODEL_490b6c7afdc7474f8f786a44bd3efe8d","value":"generation_config.json:‚Äá100%"}},"1f9ed604c26f404da6c9125f292421ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2bc10dea1644a0e9137f4260a564928","max":242,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81a35d18b7dc447ebd90400736134cc3","value":242}},"a2e2a5bc38a54447948ac063ac50e96f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57d7ffb267904838b0ad6930ceb5156a","placeholder":"‚Äã","style":"IPY_MODEL_2a1cee8108064eeea0be6c62c3f599c2","value":"‚Äá242/242‚Äá[00:00&lt;00:00,‚Äá7.06kB/s]"}},"8d984162830d4720a83641ce49441d21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"399e08741621415b940bdb04aaeac11f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"490b6c7afdc7474f8f786a44bd3efe8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2bc10dea1644a0e9137f4260a564928":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81a35d18b7dc447ebd90400736134cc3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"57d7ffb267904838b0ad6930ceb5156a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a1cee8108064eeea0be6c62c3f599c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}